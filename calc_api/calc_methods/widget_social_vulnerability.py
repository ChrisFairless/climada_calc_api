import logging
import numpy as np
import pandas as pd
from celery import chain, chord, group, shared_task
from celery_singleton import Singleton

from climada.util.api_client import Client

from calc_api.config import ClimadaCalcApiConfig
from calc_api.vizz import schemas, schemas_widgets
from calc_api.vizz.text_social_vulnerability import generate_social_vulnerability_widget_text, generate_social_vulnerability_widget_text_no_data
from calc_api.calc_methods.calc_exposure import get_exposure, subset_dataframe_extent
from calc_api.vizz.schemas_widgets import SocialVulnerabilityWidgetData, SocialVulnerabilityWidgetRequest, SocialVulnerabilityWidgetResponse
from calc_api.job_management.job_management import database_job
from calc_api.job_management.standardise_schema import standardise_schema

conf = ClimadaCalcApiConfig()

LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(getattr(logging, conf.LOG_LEVEL))


@standardise_schema
def widget_social_vulnerability(data: schemas_widgets.SocialVulnerabilityWidgetRequest):

    if data.location_poly and len(data.location_poly) != 4:
        LOGGER.warning('Ignoring location polygon data for soc vuln calculations: using location bbox')

    # TODO in the case of a country-scale calculation, I think we'll do it twice due to the location_poly attribute. Ehh
    chord_header = [
        create_socvuln_deciles.s(
            country_iso=data.geocoding.country_id,
            location_name=data.geocoding.country,
            location_poly=None
        ),
        create_socvuln_deciles.s(
            country_iso=data.geocoding.country_id,
            location_name=data.location_name,
            location_poly=data.geocoding.bbox
        )
    ]

    chord_callback = create_socvuln_widget_from_deciles.s(
        hazard_type=data.hazard_type,
        location_name=data.location_name,
        country_name=data.geocoding.country
    )

    res = chord(chord_header)(chord_callback)

    return res.id


@shared_task(base=Singleton)
@database_job   # TODO is this the right place to be cacheing?
def create_socvuln_deciles(
        country_iso,
        location_name=None,
        location_poly=None
):

    if location_poly and len(location_poly) != 4:
        LOGGER.warning("Can't handle polygons to extract social vulnerability data yet, provide a bounding box with length 4")

    # TODO maybe parallelise this
    exp_socvuln = get_soc_vuln_from_api(country_iso)
    if not exp_socvuln:
        return {
            'location': location_name,
            'vuln_range': None,
            'total_population': None,
            'n_grid_cells': None,
            'vulnerability_distribution': None
        }

    exp_litpop = get_exposure(
            country=country_iso,
            exposure_type='people',
            impact_type=None,
            scenario_name='historical',
            scenario_growth='historical',
            scenario_year='2020',
            location_poly=location_poly,
            aggregation_scale=None,
            aggregation_method=None
    )

    df_socvuln = exp_socvuln.gdf
    df_litpop = pd.DataFrame(exp_litpop)
    df_socvuln.rename(columns={'value': 'vuln', 'latitude': 'lat', 'longitude': 'lon'}, inplace=True)
    df_litpop = df_litpop[df_litpop['value'] != 0]

    n_grid_cells = df_litpop.shape[0]

    vuln_min = min(df_socvuln['vuln'])
    vuln_max = max(df_socvuln['vuln'])

    if location_poly:
        df_socvuln = subset_dataframe_extent(df_socvuln, location_poly, buffer=150, latlon_names=('lat', 'lon'))
        df_litpop = subset_dataframe_extent(df_litpop, location_poly, buffer=150, latlon_names=('lat', 'lon'))

    df_litpop['lat'] = np.round(df_litpop['lat'], 5)
    df_litpop['lon'] = np.round(df_litpop['lon'], 5)
    df_socvuln['lat'] = np.round(df_socvuln['lat'], 5)
    df_socvuln['lon'] = np.round(df_socvuln['lon'], 5)

    df_exp = df_litpop.merge(df_socvuln, on=['lat', 'lon'], how='left', copy=False)
    unmatched = np.isnan(df_exp['vuln'])
    if sum(unmatched) > 0:
        LOGGER.warning(f'Some exposure values did not match to a vulnerability, dropping these: {sum(unmatched)} / {len(df_exp)}')
        df_exp = df_exp[~unmatched]
    # exp.gdf.sort(['value'], inplace=True)
    # TODO i thought social vuln data was all in the [0,1] range. investigate
    bins = [vuln_min + i * (vuln_max - vuln_min) / 10 for i in range(10)]
    df_exp['decile'] = np.digitize(df_exp['vuln'], bins=bins)
    pop_by_decile = df_exp.groupby('decile').agg({'value': 'sum'}).reset_index()
    # TODO make this a class or a schema
    return {
        'location': location_name,
        'vuln_range': (vuln_min, vuln_max),
        'total_population': sum(pop_by_decile['value']),
        'n_grid_cells': n_grid_cells,
        'vulnerability_distribution': [
            {
                'decile': int(row['decile']),
                'value': row['value']
            } for _, row in pop_by_decile.iterrows()
        ]
    }


def get_soc_vuln_from_api(country_iso):
    request_properties = {
        'spatial_coverage': 'country',
        'country_iso3alpha': country_iso,
    }

    LOGGER.debug(
        f'Requesting relative wealth index data from Data API. Request properties: {request_properties}')
    client = Client()

    try:
        # TODO maybe make some of these parameters into settings
        soc_vuln = client.get_exposures(
            exposures_type='relative_wealth_litpop',
            properties=request_properties,
            status='preliminary',
            version='newest'
        )
    except Client.NoResult as err:
        LOGGER.warning(f'No social vulnerability data found for {country_iso}: returning None')
        return None

    return soc_vuln


@shared_task()
def create_socvuln_widget_from_deciles(
        socvuln_list,
        hazard_type,
        location_name,
        country_name):

    socvuln_country, socvuln_location = socvuln_list
    socvuln_country_deciles = socvuln_country['vulnerability_distribution']
    socvuln_location_deciles = socvuln_location['vulnerability_distribution']

    if socvuln_country['vulnerability_distribution'] is not None:  # if there's soc vuln data for this place
        widget_text = generate_social_vulnerability_widget_text(
            socvuln_location,
            socvuln_country,
            hazard_type,
            location_name
        )

        widget_bars = [
            schemas.ExposureBreakdownBar(
                label=f'Relative vulnerability breakdown for {country_name}',
                location_scale='country',
                category_labels=[d['decile'] for d in socvuln_country_deciles],
                values=[d['value'] for d in socvuln_country_deciles]
            ),
            schemas.ExposureBreakdownBar(
                label=f'Relative vulnerability breakdown for {location_name}',
                location_scale='location',
                category_labels=[d['decile'] for d in socvuln_location_deciles],
                values=[d['value'] for d in socvuln_location_deciles]
            )
        ]

        widget_legend = schemas.CategoricalLegend(
            title=f'Relative vulnerability breakdown for {location_name}',
            units=None,
            items=[
                schemas.CategoricalLegendItem(
                    label=str(i),
                    slug=str(i))
                for i in np.arange(1, 11)
            ]
        )

        widget_chart = schemas.ExposureBreakdown(
            items=widget_bars,
            legend=widget_legend
        )

    else:
        LOGGER.debug('No social vulnerability data received for widget.')
        widget_text = generate_social_vulnerability_widget_text_no_data(hazard_type)
        widget_chart = None

    widget_data = schemas_widgets.SocialVulnerabilityWidgetData(
        text=widget_text,
        chart=widget_chart
    )

    return schemas_widgets.SocialVulnerabilityWidgetResponse(
        data=widget_data,
        metadata={}
    )


def get_national_socvuln_bounds(country_iso):
    try:
        countrydata = CountryData.objects.get(country_iso3alpha=country_iso)
    except CountryData.DoesNotExist as e:
        LOGGER.warning('No country data found for ' + country_iso)
        raise CountryData.DoesNotExist(e)
    return countrydata.socvuln_min, countrydata.socvuln_max