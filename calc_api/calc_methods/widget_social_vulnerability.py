import logging
import numpy as np
from celery import chain, chord, group, shared_task
from celery_singleton import Singleton

from climada.util.api_client import Client

from calc_api.config import ClimadaCalcApiConfig
from calc_api.vizz import schemas, schemas_widgets
from calc_api.calc_methods.util import standardise_scenario
from calc_api.calc_methods.timeline import timeline_impact
from calc_api.vizz.text_timeline import generate_timeline_widget_text
from calc_api.calc_methods.geocode import standardise_location
from calc_api.calc_methods.calc_exposure import get_exposure
from calc_api.calc_methods.timeline import set_up_timeline_calculations, combine_impacts_to_timeline, combine_impacts_to_timeline_no_celery
from calc_api.calc_methods.geocode import standardise_location
from calc_api.vizz.schemas_widgets import SocialVulnerabilityWidgetData, SocialVulnerabilityWidgetRequest, SocialVulnerabilityWidgetResponse

conf = ClimadaCalcApiConfig()

LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(getattr(logging, conf.LOG_LEVEL))


def widget_social_vulnerability(data: schemas_widgets.SocialVulnerabilityWidgetRequest):
    location = standardise_location(location_name=data.location_name, location_code=data.location_id, location_poly=data.location_poly)

    chord_header = [
        get_soc_vuln_data.s(location),
        get_exposure.s(
            country=location.id,
            exposure_type='people',
            impact_type=None,
            scenario_name='historical',
            scenario_growth='historical',
            scenario_year='2020',
            location_poly=location.poly,
            aggregation_scale=None,
            aggregation_method=None)
    ]
    chord_callback = combine_exposures_to_socvuln_widget.s()

    res = chord(chord_header)(chord_callback)
    return res.id


@shared_task(base=Singleton)
def get_soc_vuln_data(location):
    if location['scale'] == 'country':
        # TODO extract by country id
        pass
    if location['scale'] == 'admin1':
        # TODO extract by admin1
        pass
    if location['poly']:
        LOGGER.warning("Can't handle polygons to extract social vulnerability data yet: falling back bounding box")
    if not location['bbox']:
        raise ValueError("Location data requires a bounding box for the moment")


def get_soc_vuln_from_api(country_iso):
    request_properties = {
        'spatial_coverage': 'country',
        'country_iso3alpha': country_iso,
    }

    LOGGER.debug(
        f'Requesting relative wealth index data from Data API. Request properties: {request_properties}')
    client = Client()

    try:
        # TODO maybe make some of these parameters into settings
        soc_vuln = client.get_exposures(
            exposures_type='relative_wealth',
            properties=request_properties,
            status='preliminary',
            version='v1'
        )
    except Client.NoResult as err:
        raise Client.NoResult(err)

    return soc_vuln


@shared_task(base=Singleton)
def combine_exposures_to_socvuln_widget(soc_vuln, exp, location):
    # class SocialVulnerabilityWidgetData(Schema):
    #     text: List[GeneratedText]
    #     chart: schemas.ExposureBreakdown
    #

    # class GeneratedText(Schema):
    #     template: str
    #     values: List[TextVariable]

    # class ExposureBreakdownRequest(Schema):
    #     exposure_type: str = None
    #     exposure_categorisation: str
    #     scenario_year: int = None
    #     location_name: str = None
    #     location_scale: str = None
    #     location_code: str = None
    #     location_poly: List[float] = None
    #     aggregation_method: str = None
    #     units: str = None
    #
    # class ExposureBreakdownBar(Schema):
    #     label: str
    #     category_labels: List[str]
    #     values: List[float]
    #
    # class ExposureBreakdown(Schema):
    #     items: List[ExposureBreakdownBar]
    #     legend: CategoricalLegend
    #
    # class ExposureBreakdownResponse(Schema):
    #     data: ExposureBreakdown
    #     metadata: dict

    soc_vuln.gdf.rename({'value': 'vuln'}, inplace=True)
    exp.gdf.merge(soc_vuln.gdf, on=['latitude', 'longitude'], how='left')
    unmatched = np.isnan(exp.gdf['vuln'])
    if sum(unmatched) > 0:
        LOGGER.warning(f'Some exposure values did not match to a vulnerability, dropping these: {sum(unmatched)} / {len(exp.gdf)}')
        exp.gdf = exp.gdf[~unmatched]
    # exp.gdf.sort(['value'], inplace=True)
    exp.gdf['decile'] = np.digitize(exp.gdf['vuln'], bins=np.arange(0, 10)/10)
    pop_by_decile = exp.gdf.groupby('decile').agg({'value': 'sum'}).reset_index()

    widget_bars = [
        # TODO give country context
        schemas.ExposureBreakdownBar(
            label=f'Relative vulnerability breakdown for {location.name}',
            category_labels=[str(i) for i in pop_by_decile['decile']],
            values=pop_by_decile['value']
        )
    ]

    widget_legend = schemas.CategoricalLegend(
        title=f'Relative vulnerability breakdown for {location.name}',
        units=None,
        items=[
            schemas.CategoricalLegendItem(
                label=str(i),
                slug=str(i),
                value=5)
            for i in np.arange(1, 11)
        ]
    )

    widget_text = generate_social_vulnerability_widget_text()

    widget_chart = schemas.ExposureBreakdown(
        items=widget_bars,
        legend=widget_legend
    )

    widget_data = schemas_widgets.SocialVulnerabilityWidgetData(
        text=widget_text,
        chart=widget_chart
    )

    return schemas_widgets.SocialVulnerabilityWidgetResponse(
        data=widget_data,
        metadata={}
    )


def widget_biodiversity(data: schemas_widgets.BiodiversityWidgetRequest):
    return {}